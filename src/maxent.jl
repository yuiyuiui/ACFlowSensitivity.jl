# ä¸€äº›è¯´æ˜Žï¼š
# 1. ä¸ºäº†æ–¹ä¾¿è®¡ç®—ï¼Œæˆ‘ä»¬ç»Ÿä¸€ä½¿ç”¨å‡åŒ€çš„è¾“å‡ºç½‘æ ¼ç‚¹ï¼Œå¹¶è®°ä¸ªç‚¹é—´è·ä¸ºd

# Directly maximum Q
function chi2kink_v1(iwn::Vector{ComplexF64}, Gvalue::Vector{ComplexF64}, output_range::Vector{Float64}; singular_space = true)
	output_number = length(output_range)
	N = length(Gvalue)

	# è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
	d = output_range[2] - output_range[1]
	output_weight = fill(d, output_number)

	# set the kernel matrix
	kernel = Matrix{ComplexF64}(undef, N, output_number)
	for i âˆˆ 1:N
		for j âˆˆ 1:output_number
			kernel[i, j] = 1 / (iwn[i] - output_range[j])
		end
	end

	# real paraliaze Gvalue and kernel
	G = vcat(real(Gvalue), imag(Gvalue))
	K = [real(kernel); imag(kernel)]

	# defualt model
	model = exp.(-output_range .^ 2 / 2)
	# è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
	model = model / (model' * output_weight)

	# é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
	Ïƒ = 1e-4

	# è®¾å®šä¸€åˆ— Î±, é•¿åº¦é»˜è®¤ä¸º20
	L = 18
	Î±_vec = Vector{Float64}(undef, L)
	Î±_vec[1] = 1e12
	for i âˆˆ 2:L
		Î±_vec[i] = Î±_vec[i-1] / 10.0
	end

	# åŽé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
	function fitfun(x, p)
		return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
	end

	# æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
	adjust = 2.5

	if singular_space

		_, S, V = svd(K)
		n = count(x -> (x >= 1e-10), S)
		V = V[:, 1:n]

		# A, Ï‡Â²å’Œuçš„å…³ç³»
		A(u::Vector{Float64}) = model .* exp.(V * u)
		Ï‡Â²(u::Vector{Float64}) = (G - K * (A(u) .* output_weight))' * (G - K * (A(u) .* output_weight)) / (Ïƒ^2)

		# è¦ä¼˜åŒ–çš„å‡½æ•°
		function Q(u::Vector{Float64}, Î±)
			SJEntropy = (A(u) - model - A(u) .* log.(A(u) ./ model))' * output_weight
			return Î± * SJEntropy - Ï‡Â²(u) / 2
		end

		# çŽ°åœ¨å¯¹äºŽæ¯ä¸€ä¸ªÎ±, å¯»æ‰¾å¯¹åº”çš„æœ€ä¼˜çš„u, (tha is to say, A), å¹¶å¾—åˆ°æ­¤æ—¶å¯¹åº”çš„Ï‡Â²
		Ï‡Â²_vec = Vector{Float64}(undef, L)
		options = Optim.Options(g_tol = 1e-5, f_tol = 1e-5)
		for i âˆˆ 1:L
			@show i
			u_opt = Optim.minimizer(optimize(u -> -Q(u, Î±_vec[i]), zeros(n), BFGS(), options))
			Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
		end


		# çŽ°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
		guess_fit = ones(4)
		_, _, c, d = curve_fit(fitfun, log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit).param


		# é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
		Î±_opt = 10.0^(c - adjust / d)
		u_opt = Optim.minimizer(optimize(u -> -Q(u, Î±_opt), zeros(n), BFGS()))
		@show Ï‡Â²(u_opt)

		#å¤åŽŸè¿”å›žè¦æ±‚çš„A
		return A(u_opt)

	else
		# this method usually doesn't work because we can't make sure we always have A>0 suring the iteration. 
		# A and Ï‡Â²
		Ï‡Â²A(A::Vector{Float64}) = (G - K * (A .* output_weight))' * (G - K * (A .* output_weight)) / (Ïƒ^2)

		# è¦ä¼˜åŒ–çš„å‡½æ•°
		QA(A::Vector{Float64}, Î±) = Î± * ((A - model - A .* log.(A ./ model))' * output_weight) - Ï‡Â²A(A) / 2

		Ï‡Â²_vec = Vector{Float64}(undef, L)
		options = Optim.Options(g_tol = 1e-5, f_tol = 1e-5)
		for i âˆˆ 1:L
			@show i
			A_opt = Optim.minimizer(optimize(A -> -QA(A, Î±_vec[i]), ones(output_number), BFGS(), options))
			Ï‡Â²_vec[i] = Ï‡Â²(A_opt)
		end


		# çŽ°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
		guess_fit = ones(4)
		_, _, c, d = curve_fit(fitfun, log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit).param


		# é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
		Î±_opt = 10.0^(c - adjust / d)
		A_opt = Optim.minimizer(optimize(u -> -QA(A, Î±_opt), ones(output_number), BFGS()))
		@show Ï‡Â²A(A_opt)
		#å¤åŽŸè¿”å›žè¦æ±‚çš„A
		return A_opt
	end
end



# wirte optimize max Q by hand for AD
function chi2kink_v2(iwn::Vector{ComplexF64}, Gvalue::Vector{ComplexF64}, output_range::Vector{Float64}; singular_space = true)
	output_number = length(output_range)
	N = length(Gvalue)

	# è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
	d = output_range[2] - output_range[1]
	output_weight = fill(d, output_number)

	# set the kernel matrix
	kernel = Matrix{ComplexF64}(undef, N, output_number)
	for i âˆˆ 1:N
		for j âˆˆ 1:output_number
			kernel[i, j] = 1 / (iwn[i] - output_range[j])
		end
	end

	# real paraliaze Gvalue and kernel
	G = vcat(real(Gvalue), imag(Gvalue))
	K = [real(kernel); imag(kernel)]
	_, S, V = svd(K)
	n = count(x -> (x >= 1e-10), S)
	V = V[:, 1:n]

	# defualt model
	model = exp.(-output_range .^ 2 / 2)
	# è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
	model = model / (model' * output_weight)

	# é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
	Ïƒ = 1e-4

	# è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
	L = 18
	Î±_vec = Vector{Float64}(undef, L)
	Î±_vec[1] = 1e12
	for i âˆˆ 2:L
		Î±_vec[i] = Î±_vec[i-1] / 10.0
	end
	Ï‡Â²_vec = Vector{Float64}(undef, L)

	# åŽé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
	function fitfun(x, p)
		return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
	end

	# æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
	adjust = 2.5

	# function Q
	A(u::Vector{Float64}) = model .* exp.(V * u)
	Ï‡Â²(u::Vector{Float64}) = (G - d * K * A(u))' * (G - d * K * A(u)) / (Ïƒ^2)
	Q(u::Vector{Float64}, Î±::Float64) = Î± * (A(u) - model - A(u) .* log.(A(u) ./ model))' * output_weight - 0.5 * Ï‡Â²(u)

	# ðž‰Q/âˆ‚u
	function âˆ‚Qdivâˆ‚u(u::Vector{Float64}, Î±::Float64)
		âˆ‚Sdivâˆ‚A = -d * (V * u)'    #è¡Œå‘é‡	
		âˆ‚Ï‡Â²divâˆ‚A = 2 / (Ïƒ^2) * (-d * G' * K + d^2 * A(u)' * K' * K)    #è¡Œå‘é‡
		âˆ‚Adivâˆ‚u = diagm(A(u)) * V
		âˆ‚Sdivâˆ‚u = âˆ‚Sdivâˆ‚A * âˆ‚Adivâˆ‚u
		âˆ‚Ï‡Â²divâˆ‚u = âˆ‚Ï‡Â²divâˆ‚A * âˆ‚Adivâˆ‚u

		return (Î± * âˆ‚Sdivâˆ‚u - âˆ‚Ï‡Â²divâˆ‚u / 2)'
	end


	# æŽ¥ä¸‹æ¥ç”¨BFGSæ±‚æœ€å€¼ç‚¹
	for i in 1:L
		@show i
		Î± = Î±_vec
		u_opt = my_BFGS(u -> -Q(u, Î±_vec[i]), u -> -âˆ‚Qdivâˆ‚u(u, Î±_vec[i]), zeros(n))
		Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
	end

	# çŽ°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
	guess_fit = ones(4)
	_, _, c, d = curve_fit(fitfun, log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit).param


	# é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
	Î±_opt = 10.0^(c - adjust / d)
	u_opt = my_BFGS(u -> -Q(u, Î±_opt), u -> -âˆ‚Qdivâˆ‚u(u, Î±_opt), model)
	@show Ï‡Â²(u_opt)

	#å¤åŽŸè¿”å›žè¦æ±‚çš„A
	return A(u_opt)
end







function my_likehood(iwn::Vector{ComplexF64}, Gvalue::Vector{ComplexF64}, output_range::Vector{Float64}; singular_space = true)
	output_number = length(output_range)
	N = length(Gvalue)

	# è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
	output_weight = zero(output_range)
	output_weight[1] = output_range[2] - output_range[1]
	output_weight[end] = output_range[end] - output_range[end-1]
	output_weight[2:end-1] = (output_range[3:end] - output_range[1:end-2]) / 2

	# set the kernel matrix
	kernel = Matrix{ComplexF64}(undef, N, output_number)
	for i âˆˆ 1:N
		for j âˆˆ 1:output_number
			kernel[i, j] = 1 / (iwn[i] - output_range[j])
		end
	end

	# real paraliaze Gvalue and kernel
	G = vcat(real(Gvalue), imag(Gvalue))
	K = [real(kernel); imag(kernel)]

	if singular_space
		_, S, V = svd(K)
		n = count(x -> (x >= 1e-12), S)
		V = V[:, 1:n]

		# defualt model
		model = exp.(-output_range .^ 2 / 2)
		# è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
		model = model / (model' * output_weight)
		#=
		A(u::Vector{Float64}) = model .* exp.(V * u)
		Ï‡Â²(u::Vector{Float64}) = (G - K * (A(u) .* output_weight))' * (G - K * (A(u) .* output_weight)) *1e10
		=#

		Ï‡Â²(u::Vector{Float64}) = (G - K * ((V * u) .* output_weight))' * (G - K * ((V * u) .* output_weight)) * 1e12


		u_opt = Optim.minimizer(optimize(u -> Ï‡Â²(u), zeros(n), BFGS()))
		@show Ï‡Â²(u_opt)

		return V * u_opt
	else
		Ï‡Â²A(A::Vector{Float64}) = (G - K * (A .* output_weight))' * (G - K * (A .* output_weight)) * 1e10

		A_opt = Optim.minimizer(optimize(Ï‡Â²A, zeros(output_number), BFGS()))
		@show Ï‡Â²A(A_opt)
		return A_opt
	end

end


#=
values0 = map(int_field) do z
		C = 1 ./ (z .- iwn0)
		return sum(C .* w_times_f) / sum(C .* weights)
	end
=#












