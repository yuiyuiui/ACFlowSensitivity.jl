function solve(GFV::Vector{Complex{T}}, ctx::CtxData{T}, alg::MaxEntChi2kink) where {T<:Real}
    L = alg.L
    Î±â‚ = T(alg.Î±â‚)
    Ïƒ = T(alg.Ïƒ)
    M = length(ctx.mesh)
    maxiter = alg.maxent_iter

    # singular space method
    kernel = Matrix{Complex{T}}(undef, length(GFV), length(ctx.mesh))
    for i âˆˆ 1:length(GFV)
        for j âˆˆ 1:length(ctx.mesh)
            kernel[i, j] = 1 / (ctx.iwn[i] - ctx.mesh[j])
        end
    end
    G = vcat(real(GFV), imag(GFV))
    K = [real(kernel); imag(kernel)]
    U, S, V = svd(K)
    n = count(x -> (x >= strict_tol(T))/10, S)
    V = V[:, 1:n]
    U = U[:, 1:n]
    S = S[1:n]
    
    model = make_model(alg.model_type, ctx)
    reA = copy(model)
    for i âˆˆ 1:maxiter
        model = reA
        reA = chi2kink(G,K,n,U,S,V,model,ctx.mesh_weights,L,Î±â‚,Ïƒ)
    end
end



function chi2kink(G::Vector{T},K::Matrix{T},n::Int,U::Matrix{T},S::Vector{T},V::Matrix{T},model::Vector{T},w::Vector{T},L::Int,Î±â‚::T,Ïƒ::T) where {T<:Real}

    Î±_vec = Vector{T}(undef, L)
    Î±_vec[1] = Î±â‚
    for i âˆˆ 2:L
        Î±_vec[i] = Î±_vec[i-1] / 10
    end
    Ï‡Â²_vec = Vector{T}(undef, L)

    # åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
    function fitfun(x, p)
        return @. p[1] + p[2] / (1 + exp(-p[4] * (x - p[3])))
    end

    # æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
    #adjust = T(2.5)

    # function Q
    A_vec(u::Vector{T}) = model .* exp.(V * u)
    Ï‡Â²(u::Vector{T}) = (G - K * A_vec(u))' * (G - K * A_vec(u)) / (Ïƒ^2)
    Q(u::Vector{T}, Î±::T) = Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * w - 0.5 * Ï‡Â²(u)

    # -ğ‰Q/âˆ‚A
    J(u::Vector{Float64}, Î±::Float64) =
        Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

    # -âˆ‚Â²Q/âˆ‚Aâˆ‚u
    H(u::Vector{Float64}, Î±::Float64) =
        Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V



    # æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
    u_guess = zeros(n)
    u_opt_vec = Vector{Vector{Float64}}(undef, L)
    for i = 1:L
        # @show i
        Î± = Î±_vec[i]
        u_opt, call, _ = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
        u_guess = copy(u_opt)
        u_opt_vec[i] = copy(u_opt)
        Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
        # @show log10(Î±), log10(Ï‡Â²_vec[i]), norm(J(u_opt, Î±)), call
    end
    idx = findall(isfinite, Ï‡Â²_vec)
    Î±_vec = Î±_vec[idx]
    Ï‡Â²_vec = Ï‡Â²_vec[idx]
    u_opt_vec = u_opt_vec[idx]

    # ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
    guess_fit = [0.0, 5.0, 2.0, 0.0]
    _, _, c, dd = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())[1]


    # é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
    Î±_opt = 10.0^(c)
    u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
    u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

    #å¤åŸè¿”å›è¦æ±‚çš„A
    return A_vec(u_opt)
end

function my_chi2kink(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64},
)
    output_number = length(output_range)
    N = length(Gvalue)

    # è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
    d = output_range[2] - output_range[1]
    output_weight = fill(d, output_number)

    

    # defualt model
    model = exp.(-output_range .^ 2 / 4)
    # è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
    model = model / (model' * output_weight)

    # é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
    Ïƒ = 1e-4

    # è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
    L = 16
    Î±_vec = Vector{Float64}(undef, L)
    Î±_vec[1] = 1e12
    for i âˆˆ 2:L
        Î±_vec[i] = Î±_vec[i-1] / 10.0
    end
    Ï‡Â²_vec = Vector{Float64}(undef, L)

    # åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
    function fitfun(x, p)
        return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
    end

    # æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
    #adjust = 2.5


    # function Q
    A_vec(u::Vector{Float64}) = model .* exp.(V * u)
    Ï‡Â²(u::Vector{Float64}) = (G - d * K * A_vec(u))' * (G - d * K * A_vec(u)) / (Ïƒ^2)
    Q(u::Vector{Float64}, Î±::Float64) =
        Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * output_weight -
        0.5 * Ï‡Â²(u)

    # -ğ‰Q/âˆ‚A
    J(u::Vector{Float64}, Î±::Float64) =
        Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

    # -âˆ‚Â²Q/âˆ‚Aâˆ‚u
    H(u::Vector{Float64}, Î±::Float64) =
        Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V



    # æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
    u_guess = zeros(n)
    u_opt_vec = Vector{Vector{Float64}}(undef, L)
    for i = 1:L
        # @show i
        Î± = Î±_vec[i]
        u_opt, call, _ = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
        u_guess = copy(u_opt)
        u_opt_vec[i] = copy(u_opt)
        Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
        # @show log10(Î±), log10(Ï‡Â²_vec[i]), norm(J(u_opt, Î±)), call
    end
    idx = findall(isfinite, Ï‡Â²_vec)
    Î±_vec = Î±_vec[idx]
    Ï‡Â²_vec = Ï‡Â²_vec[idx]
    u_opt_vec = u_opt_vec[idx]

    # ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
    guess_fit = [0.0, 5.0, 2.0, 0.0]
    _, _, c, dd = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())[1]


    # é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
    Î±_opt = 10.0^(c)
    u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
    u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

    #å¤åŸè¿”å›è¦æ±‚çš„A
    return A_vec(u_opt)
end
#


function my_chi2kink_v2(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64};
    model_ite = 0,
)
    output_number = length(output_range)
    N = length(Gvalue)

    # è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
    d = output_range[2] - output_range[1]
    output_weight = fill(d, output_number)

    # set the kernel matrix
    kernel = Matrix{ComplexF64}(undef, N, output_number)
    for i âˆˆ 1:N
        for j âˆˆ 1:output_number
            kernel[i, j] = 1 / (iwn[i] - output_range[j])
        end
    end

    # real paraliaze Gvalue and kernel
    G = vcat(real(Gvalue), imag(Gvalue))
    K = [real(kernel); imag(kernel)]
    U, S, V = svd(K)
    n = count(x -> (x >= 1e-10), S)
    V = V[:, 1:n]
    U = U[:, 1:n]
    S = S[1:n]

    # é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
    Ïƒ = 1e-4

    # è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
    L = 16
    A_res = zeros(N)

    for t âˆˆ 0:model_ite
        println("model iter =  $t")
        if t == 0
            model = exp.(-output_range .^ 2 / 4)
            model = model / (model' * output_weight)
        else
            model = copy(A_res)
        end

        Î±_vec = Vector{Float64}(undef, L)
        Î±_vec[1] = 1e12
        for i âˆˆ 2:L
            Î±_vec[i] = Î±_vec[i-1] / 10.0
        end
        Ï‡Â²_vec = Vector{Float64}(undef, L)

        # åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
        function fitfun(x, p)
            return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
        end

        # æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
        #adjust = 2.5


        # function Q
        A_vec(u::Vector{Float64}) = model .* exp.(V * u)
        Ï‡Â²(u::Vector{Float64}) = (G - d * K * A_vec(u))' * (G - d * K * A_vec(u)) / (Ïƒ^2)
        Q(u::Vector{Float64}, Î±::Float64) =
            Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * output_weight -
            0.5 * Ï‡Â²(u)

        # -ğ‰Q/âˆ‚A
        J(u::Vector{Float64}, Î±::Float64) =
            Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

        # -âˆ‚Â²Q/âˆ‚Aâˆ‚u
        H(u::Vector{Float64}, Î±::Float64) =
            Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V



        # æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
        u_guess = zeros(n)
        u_opt_vec = Vector{Vector{Float64}}(undef, L)
        for i = 1:L
            Î± = Î±_vec[i]
            u_opt, call, _ = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
            u_guess = copy(u_opt)
            u_opt_vec[i] = copy(u_opt)
            Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
        end
        idx = findall(isfinite, Ï‡Â²_vec)
        Î±_vec = Î±_vec[idx]
        Ï‡Â²_vec = Ï‡Â²_vec[idx]
        u_opt_vec = u_opt_vec[idx]

        # ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
        guess_fit = [0.0, 5.0, 2.0, 0.0]
        _, _, c, dd = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())[1]


        # é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
        Î±_opt = 10.0^(c)
        u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
        u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

        #å¤åŸè¿”å›è¦æ±‚çš„A
        A_res = A_vec(u_opt)
    end
    return A_res
end



function ADchi2kink(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64},
)
    dAdivdG, dlossdivdG = _ADchi2kink(iwn, Gvalue, output_range)
    @show norm(dAdivdG)
    return dAdivdG, dlossdivdG
end

function _ADchi2kink(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64},
)
    output_number = length(output_range)
    N = length(Gvalue)

    # è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
    d = output_range[2] - output_range[1]
    output_weight = fill(d, output_number)

    # set the kernel matrix
    kernel = Matrix{ComplexF64}(undef, N, output_number)
    for i âˆˆ 1:N
        for j âˆˆ 1:output_number
            kernel[i, j] = 1 / (iwn[i] - output_range[j])
        end
    end

    # real paraliaze Gvalue and kernel
    G = vcat(real(Gvalue), imag(Gvalue))
    K = [real(kernel); imag(kernel)]
    U, S, V = svd(K)
    n = count(x -> (x >= 1e-10), S)
    V = V[:, 1:n]
    U = U[:, 1:n]
    S = S[1:n]

    # defualt model
    model = exp.(-output_range .^ 2 / 4)
    # è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
    model = model / (model' * output_weight)

    # é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
    Ïƒ = 1e-4

    # è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
    L = 16
    Î±_vec = Vector{Float64}(undef, L)
    Î±_vec[1] = 1e12
    for i âˆˆ 2:L
        Î±_vec[i] = Î±_vec[i-1] / 10.0
    end
    Ï‡Â²_vec = Vector{Float64}(undef, L)

    # åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
    function fitfun(x, p)
        return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
    end

    # æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
    #adjust = 2.5


    # function Q
    A_vec(u::Vector{Float64}) = model .* exp.(V * u)
    Ï‡Â²(u::Vector{Float64}) = (G - d * K * A_vec(u))' * (G - d * K * A_vec(u)) / (Ïƒ^2)
    Q(u::Vector{Float64}, Î±::Float64) =
        Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * output_weight -
        0.5 * Ï‡Â²(u)

    # -ğ‰Q/âˆ‚A, what we get is a vector, that is to say, column vector
    J(u::Vector{Float64}, Î±::Float64) =
        Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

    # -âˆ‚Â²Q/âˆ‚Aâˆ‚u, âˆ‚f/âˆ‚u
    H(u::Vector{Float64}, Î±::Float64) =
        Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V

    # âˆ‚Ï‡Â²/âˆ‚A, get a row vector
    âˆ‚Ï‡Â²divâˆ‚A(u::Vector{Float64}) =
        Matrix(2 / (Ïƒ^2) * (-d * G' * K + d^2 * A_vec(u)' * V * diagm(S .^ 2) * V'))

    # âˆ‚A/âˆ‚u 
    âˆ‚Adivâˆ‚u(u::Vector{Float64}) = diagm(A_vec(u)) * V

    # âˆ‚f/âˆ‚G 
    âˆ‚fdivâˆ‚G = -1 / (Ïƒ^2) * diagm(S) * U'

    # âˆ‚Ï‡Â²/âˆ‚G, get a row vector
    âˆ‚Ï‡Â²divâˆ‚G(u::Vector{Float64}) = Matrix(2 / (Ïƒ^2) * (G' - d * A_vec(u)' * K'))

    # dÏ‡Â²/dG 
    dÏ‡Â²divdG(u::Vector{Float64}, Î±::Float64) =
        -âˆ‚Ï‡Â²divâˆ‚A(u) * âˆ‚Adivâˆ‚u(u) * pinv(H(u, Î±)) * âˆ‚fdivâˆ‚G + âˆ‚Ï‡Â²divâˆ‚G(u)

    âˆ‚Ï‡Â²OPTdivâˆ‚G = Matrix{Float64}(undef, L, 2 * N)

    # æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
    u_guess = zeros(n)
    u_opt_vec = Vector{Vector{Float64}}(undef, L)
    for i = 1:L
        Î± = Î±_vec[i]
        u_opt, = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
        u_guess = copy(u_opt)
        u_opt_vec[i] = copy(u_opt)
        Ï‡Â²_vec[i] = Ï‡Â²(u_opt)

        if i == L && !all(isfinite, A_vec(u_opt))
            Ï‡Â²_vec[i] = NaN
            âˆ‚Ï‡Â²OPTdivâˆ‚G = âˆ‚Ï‡Â²OPTdivâˆ‚G[1:(L-1), :]
            break
        end
        âˆ‚Ï‡Â²OPTdivâˆ‚G[i, :] = dÏ‡Â²divdG(u_opt, Î±)
    end
    idx = findall(isfinite, Ï‡Â²_vec)
    Î±_vec = Î±_vec[idx]
    Ï‡Â²_vec = Ï‡Â²_vec[idx]
    u_opt_vec = u_opt_vec[idx]


    # ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
    guess_fit = [0.0, 5.0, 2.0, 0.0]
    param, _, reach_tol = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())
    _, _, c, _ = param


    # é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
    Î±_opt = 10.0^(c)
    u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
    u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

    #å¤åŸè¿”å›è¦æ±‚çš„A
    A_opt = A_vec(u_opt)
    #=
    function _Î±_opt(Ï‡Â²_vec1::Vector{Float64})
    	_, _, c, _ = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec1), guess_fit, Newton())[1]
    	Î±_opt = 10.0^(c)
    	return Î±_opt
    end
    dÎ±_optdivdÏ‡Â²_vec = Zygote.gradient(_Î±_opt, Ï‡Â²_vec)[1]
    =#

    #param = param  + [0.0,0.01,0.0,0.1]
    arg = (param, log10.(Î±_vec), log10.(Ï‡Â²_vec))
    dpdivdÏ‡Â²_vec =
        -pinv(âˆ‚Â²loss_curveDivâˆ‚pÂ²(arg...)) *
        âˆ‚Â²loss_âˆ‚pâˆ‚y(arg...) *
        diagm(1 ./ (Ï‡Â²_vec * log(10)))
    dcdivdÏ‡Â²_vec = dpdivdÏ‡Â²_vec[3, :]'
    dÎ±_optdivdÏ‡Â²_vec = Î±_opt * log(10) * dcdivdÏ‡Â²_vec

    dÎ±_optdivdG = dÎ±_optdivdÏ‡Â²_vec * âˆ‚Ï‡Â²OPTdivâˆ‚G
    du_optdivdG = -pinv(H(u_opt, Î±_opt)) * (âˆ‚fdivâˆ‚G + u_opt * dÎ±_optdivdG)
    dA_optdivdG = âˆ‚Adivâˆ‚u(u_opt) * du_optdivdG

    # loss function = ||A1 -A0||_2
    _, S1, V1 = svd(dA_optdivdG)
    dlossdivdG = V1[:, 1] * S1[1] * sqrt(d)

    return dA_optdivdG[:, 1:N] + im * dA_optdivdG[:, (N+1):(2*N)],
    dlossdivdG[1:N] + im * dlossdivdG[(N+1):(2*N)]
end




function ADchi2kink_v2(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64},
)
    c_grad, _ = _ADchi2kink_v2(iwn, Gvalue, output_range)
    @show norm(c_grad)
    return c_grad
end

function _ADchi2kink_v2(
    iwn::Vector{ComplexF64},
    Gvalue::Vector{ComplexF64},
    output_range::Vector{Float64},
)
    output_number = length(output_range)
    N = length(Gvalue)

    # è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
    d = output_range[2] - output_range[1]
    output_weight = fill(d, output_number)

    # set the kernel matrix
    kernel = Matrix{ComplexF64}(undef, N, output_number)
    for i âˆˆ 1:N
        for j âˆˆ 1:output_number
            kernel[i, j] = 1 / (iwn[i] - output_range[j])
        end
    end

    # real paraliaze Gvalue and kernel
    G = vcat(real(Gvalue), imag(Gvalue))
    K = [real(kernel); imag(kernel)]
    U, S, V = svd(K)
    n = count(x -> (x >= 1e-10), S)
    V = V[:, 1:n]
    U = U[:, 1:n]
    S = S[1:n]

    # defualt model
    model = exp.(-output_range .^ 2 / 4)
    # è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
    model = model / (model' * output_weight)

    # é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
    Ïƒ = 1e-4

    # è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
    L = 16
    Î±_vec = Vector{Float64}(undef, L)
    Î±_vec[1] = 1e12
    for i âˆˆ 2:L
        Î±_vec[i] = Î±_vec[i-1] / 10.0
    end
    Ï‡Â²_vec = Vector{Float64}(undef, L)

    # åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
    function fitfun(x, p)
        return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
    end

    # æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
    #adjust = 2.5


    # function Q
    A_vec(u::Vector{Float64}) = model .* exp.(V * u)
    Ï‡Â²(u::Vector{Float64}) = (G - d * K * A_vec(u))' * (G - d * K * A_vec(u)) / (Ïƒ^2)
    Q(u::Vector{Float64}, Î±::Float64) =
        Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * output_weight -
        0.5 * Ï‡Â²(u)

    # -ğ‰Q/âˆ‚A, what we get is a vector, that is to say, column vector
    J(u::Vector{Float64}, Î±::Float64) =
        Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

    # -âˆ‚Â²Q/âˆ‚Aâˆ‚u, âˆ‚f/âˆ‚u
    H(u::Vector{Float64}, Î±::Float64) =
        Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V

    # âˆ‚Ï‡Â²/âˆ‚A, get a row vector
    âˆ‚Ï‡Â²divâˆ‚A(u::Vector{Float64}) =
        Matrix(2 / (Ïƒ^2) * (-d * G' * K + d^2 * A_vec(u)' * V * diagm(S .^ 2) * V'))

    # âˆ‚A/âˆ‚u 
    âˆ‚Adivâˆ‚u(u::Vector{Float64}) = diagm(A_vec(u)) * V

    # âˆ‚f/âˆ‚G 
    âˆ‚fdivâˆ‚G = -1 / (Ïƒ^2) * diagm(S) * U'

    # âˆ‚Ï‡Â²/âˆ‚G, get a row vector
    âˆ‚Ï‡Â²divâˆ‚G(u::Vector{Float64}) = Matrix(2 / (Ïƒ^2) * (G' - d * A_vec(u)' * K'))

    # dÏ‡Â²/dG 
    dÏ‡Â²divdG(u::Vector{Float64}, Î±::Float64) =
        -âˆ‚Ï‡Â²divâˆ‚A(u) * âˆ‚Adivâˆ‚u(u) * pinv(H(u, Î±)) * âˆ‚fdivâˆ‚G + âˆ‚Ï‡Â²divâˆ‚G(u)

    âˆ‚Ï‡Â²OPTdivâˆ‚G = Matrix{Float64}(undef, L, 2 * N)

    # æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
    u_guess = zeros(n)
    u_opt_vec = Vector{Vector{Float64}}(undef, L)
    for i = 1:L
        Î± = Î±_vec[i]
        u_opt, = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
        u_guess = copy(u_opt)
        u_opt_vec[i] = copy(u_opt)
        Ï‡Â²_vec[i] = Ï‡Â²(u_opt)

        if i == L && !all(isfinite, A_vec(u_opt))
            Ï‡Â²_vec[i] = NaN
            âˆ‚Ï‡Â²OPTdivâˆ‚G = âˆ‚Ï‡Â²OPTdivâˆ‚G[1:(L-1), :]
            break
        end
        âˆ‚Ï‡Â²OPTdivâˆ‚G[i, :] = dÏ‡Â²divdG(u_opt, Î±)
    end
    idx = findall(isfinite, Ï‡Â²_vec)
    Î±_vec = Î±_vec[idx]
    Ï‡Â²_vec = Ï‡Â²_vec[idx]
    u_opt_vec = u_opt_vec[idx]


    # ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
    guess_fit = [0.0, 5.0, 2.0, 0.0]
    param, _, reach_tol = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())
    _, _, c, _ = param


    # é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
    Î±_opt = 10.0^(c)
    u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
    u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

    #å¤åŸè¿”å›è¦æ±‚çš„A
    A_opt = A_vec(u_opt)
    #=
    function _Î±_opt(Ï‡Â²_vec1::Vector{Float64})
    	_, _, c, _ = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec1), guess_fit, Newton())[1]
    	Î±_opt = 10.0^(c)
    	return Î±_opt
    end
    dÎ±_optdivdÏ‡Â²_vec = Zygote.gradient(_Î±_opt, Ï‡Â²_vec)[1]
    =#

    #param = param  + [0.0,0.01,0.0,0.1]
    arg = (param, log10.(Î±_vec), log10.(Ï‡Â²_vec))
    dpdivdÏ‡Â²_vec =
        -pinv(âˆ‚Â²loss_curveDivâˆ‚pÂ²(arg...)) *
        âˆ‚Â²loss_âˆ‚pâˆ‚y(arg...) *
        diagm(1 ./ (Ï‡Â²_vec * log(10)))
    dcdivdÏ‡Â²_vec = dpdivdÏ‡Â²_vec[3, :]'
    dÎ±_optdivdÏ‡Â²_vec = Î±_opt * log(10) * dcdivdÏ‡Â²_vec

    dÎ±_optdivdG = dÎ±_optdivdÏ‡Â²_vec * âˆ‚Ï‡Â²OPTdivâˆ‚G
    du_optdivdG = -pinv(H(u_opt, Î±_opt)) * (âˆ‚fdivâˆ‚G + u_opt * dÎ±_optdivdG)
    dA_optdivdG = âˆ‚Adivâˆ‚u(u_opt) * du_optdivdG

    function _loss(A_opt1::Vector)
        idx = findall(x -> x > 1e-6, A_opt)
        return sum(exp.(A_opt1[idx] - A_opt[idx]))*d
    end

    # output as a vector
    dlossdivdA_opt = Zygote.gradient(_loss, A_opt)[1]
    res = (dA_optdivdG)' * dlossdivdA_opt
    return res[1:N] + im * res[(N+1):(2*N)], reach_tol
end


function âˆ‚Â²loss_curveDivâˆ‚pÂ²(p, x, y)
    a, b, c, d = p
    L = length(x)

    # è®¡ç®— sigmoid å‡½æ•°åŠå…¶ç›¸å…³é¡¹
    s = 1 ./ (1 .+ exp.(-d * (x .- c)))
    s1 = s .* (1 .- s)  # s1 = s * (1 - s)
    r = a .+ b * s .- y  # æ®‹å·®é¡¹

    # å¡«å……å¯¹è§’å…ƒç´ 
    Jaa = 2 * L
    Jbb = 2 * sum(s .^ 2)
    Jcc =
        2 * b^2 * d^2 * sum(s .^ 2 .* (1 .- s) .^ 2) +
        2 * b * d^2 * sum(s1 .* (1 .- 2 * s) .* r)
    Jdd =
        2 * sum(
            b^2 * s .^ 2 .* (1 .- s) .^ 2 .* (x .- c) .^ 2 +
            b * (x .- c) .^ 2 .* s1 .* (1 .- 2 * s) .* r,
        )

    # å¡«å……éå¯¹è§’å…ƒç´ 
    Jab = 2 * sum(s)
    Jac = -2 * b * d * sum(s1)
    Jad = 2 * b * sum(s1 .* (x .- c))
    Jbc = -2 * d * sum(s1 .* (b * s .+ r))
    Jbd = 2 * sum(s1 .* (x .- c) .* (b * s .+ r))
    Jcd =
        -2 *
        b *
        sum(s1 .* (b * d * s1 .* (x .- c) .+ (1 .+ d * (x .- c) .* (1 .- 2 * s)) .* r))

    return [Jaa Jab Jac Jad; Jab Jbb Jbc Jbd; Jac Jbc Jcc Jcd; Jad Jbd Jcd Jdd]
end


function âˆ‚Â²loss_âˆ‚pâˆ‚y(p, x, y)
    a, b, c, d = p
    L = length(x)

    # è®¡ç®— sigmoid å‡½æ•°åŠå…¶ç›¸å…³é¡¹
    s = 1 ./ (1 .+ exp.(-d * (x .- c)))
    s1 = s .* (1 .- s)  # s1 = s * (1 - s)

    # åˆå§‹åŒ–æ··åˆåå¯¼æ•°çŸ©é˜µ
    âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix = zeros(4, L)

    # å¡«å……çŸ©é˜µ
    âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix[1, :] .= -2  # âˆ‚Â²loss/âˆ‚aâˆ‚y_i
    âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix[2, :] = -2 * s  # âˆ‚Â²loss/âˆ‚bâˆ‚y_i
    âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix[3, :] = 2 * b * d * s1  # âˆ‚Â²loss/âˆ‚câˆ‚y_i
    âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix[4, :] = -2 * b * s1 .* (x .- c)  # âˆ‚Â²loss/âˆ‚dâˆ‚y_i

    return âˆ‚Â²loss_âˆ‚pâˆ‚y_matrix
end


#=
function ADchi2kink(iwn::Vector{ComplexF64}, Gvalue::Vector{ComplexF64}, output_range::Vector{Float64})
	N = length(Gvalue)
	Try_num = 1
	noise = 0.0
	c_grad_opt = zeros(ComplexF64, N)
	min_grad = Inf
	fit_res = false
	for i âˆˆ 1:Try_num
		Gvalue += Gvalue .* rand(N) * noise .* exp.(2Ï€ * im * rand(N))
		c_grad, reach_tol = _ADchi2kink(iwn, Gvalue, output_range)
		@show norm(c_grad)
		if !reach_tol && norm(c_grad) < min_grad
			fit_res = true
			c_grad_opt = copy(c_grad)
			min_grad = norm(c_grad)
		end
	end
	!fit_res && error("No fit sensitivity analysis found, please try it again!")
	return c_grad_opt
end



function _ADchi2kink(iwn::Vector{ComplexF64}, Gvalue::Vector{ComplexF64}, output_range::Vector{Float64})
	output_number = length(output_range)
	N = length(Gvalue)

	# è®¡ç®—ç§¯åˆ†æ—¶å€™ç½‘æ ¼ç‚¹çš„æƒé‡
	d = output_range[2] - output_range[1]
	output_weight = fill(d, output_number)

	# set the kernel matrix
	kernel = Matrix{ComplexF64}(undef, N, output_number)
	for i âˆˆ 1:N
		for j âˆˆ 1:output_number
			kernel[i, j] = 1 / (iwn[i] - output_range[j])
		end
	end

	# real paraliaze Gvalue and kernel
	G = vcat(real(Gvalue), imag(Gvalue))
	K = [real(kernel); imag(kernel)]
	U, S, V = svd(K)
	n = count(x -> (x >= 1e-10), S)
	V = V[:, 1:n]
	U = U[:, 1:n]
	S = S[1:n]

	# defualt model
	model = exp.(-output_range .^ 2 / 4)
	# è°ƒæ•´å‚æ•°ï¼Œå½’ä¸€åŒ–
	model = model / (model' * output_weight)

	# é»˜è®¤æµ‹é‡Green function values on image axisæ—¶ï¼Œå„ä¸ªæµ‹é‡å€¼çš„æ ‡å‡†å·®æ˜¯1e-4
	Ïƒ = 1e-4

	# è®¾å®šä¸€åˆ— Î±, ä»¥åŠå¯¹åº”çš„Ï‡Â², é•¿åº¦é»˜è®¤
	L = 16
	Î±_vec = Vector{Float64}(undef, L)
	Î±_vec[1] = 1e12
	for i âˆˆ 2:L
		Î±_vec[i] = Î±_vec[i-1] / 10.0
	end
	Ï‡Â²_vec = Vector{Float64}(undef, L)

	# åé¢log10(Î±)å’Œlog10(Ï‡Â²)è¦æ‹Ÿåˆçš„æ›²çº¿
	function fitfun(x, p)
		return @. p[1] + p[2] / (1.0 + exp(-p[4] * (x - p[3])))
	end

	# æ‹Ÿåˆæ›²çº¿æ—¶å€™ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆè®¾ç½®çš„å‚æ•°
	#adjust = 2.5


	# function Q
	A_vec(u::Vector{Float64}) = model .* exp.(V * u)
	Ï‡Â²(u::Vector{Float64}) = (G - d * K * A_vec(u))' * (G - d * K * A_vec(u)) / (Ïƒ^2)
	Q(u::Vector{Float64}, Î±::Float64) = Î± * (A_vec(u) - model - A_vec(u) .* log.(A_vec(u) ./ model))' * output_weight - 0.5 * Ï‡Â²(u)

	# -ğ‰Q/âˆ‚A, what we get is a vector, that is to say, column vector
	J(u::Vector{Float64}, Î±::Float64) = Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))

	# -âˆ‚Â²Q/âˆ‚Aâˆ‚u, -âˆ‚f/âˆ‚u
	H(u::Vector{Float64}, Î±::Float64) = Î± * Matrix(I(n)) + d / (Ïƒ^2) * diagm(S)^2 * V' * diagm(A_vec(u)) * V

	# âˆ‚Ï‡Â²/âˆ‚A, get a row vector
	âˆ‚Ï‡Â²divâˆ‚A(u::Vector{Float64}) = Matrix(2 / (Ïƒ^2) * (-d * G' * K + d^2 * A_vec(u)' * V * diagm(S .^ 2) * V'))

	# âˆ‚A/âˆ‚u 
	âˆ‚Adivâˆ‚u(u::Vector{Float64}) = diagm(A_vec(u)) * V

	# âˆ‚f/âˆ‚G 
	âˆ‚fdivâˆ‚G = -1 / (Ïƒ^2) * diagm(S) * U'

	# âˆ‚Ï‡Â²/âˆ‚G, get a row vector
	âˆ‚Ï‡Â²divâˆ‚G(u::Vector{Float64}) = Matrix(2 / (Ïƒ^2) * (G' - d * A_vec(u)' * K'))

	# dÏ‡Â²/dG 
	dÏ‡Â²divdG(u::Vector{Float64}, Î±::Float64) = -âˆ‚Ï‡Â²divâˆ‚A(u) * âˆ‚Adivâˆ‚u(u) * pinv(H(u, Î±)) * âˆ‚fdivâˆ‚G + âˆ‚Ï‡Â²divâˆ‚G(u)

	âˆ‚Ï‡Â²OPTdivâˆ‚G = Matrix{Float64}(undef, L, 2 * N)

	# æ¥ä¸‹æ¥ç”¨Newton methodæ±‚æœ€å€¼ç‚¹
	u_guess = zeros(n)
	u_opt_vec = Vector{Vector{Float64}}(undef, L)
	for i in 1:L
		Î± = Î±_vec[i]
		u_opt, = my_newton(u -> J(u, Î±), u -> H(u, Î±), u_guess)
		u_guess = copy(u_opt)
		u_opt_vec[i] = copy(u_opt)
		Ï‡Â²_vec[i] = Ï‡Â²(u_opt)
		âˆ‚Ï‡Â²OPTdivâˆ‚G[i, :] = dÏ‡Â²divdG(u_opt, Î±)
	end
	idx = findall(isfinite, Ï‡Â²_vec)
	Î±_vec = Î±_vec[idx]
	Ï‡Â²_vec = Ï‡Â²_vec[idx]
	u_opt_vec = u_opt_vec[idx]


	# ç°åœ¨è¿›è¡Œæ›²çº¿æ‹Ÿåˆ
	guess_fit = [0.0, 5.0, 2.0, 0.0]
	param, _, reach_tol = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec), guess_fit, Newton())
	_, _, c, _ = param


	# é€‰å–æ‹ç‚¹ï¼Œå¹¶ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆæˆ–è€…æ¬ æ‹Ÿåˆåšä¸€å®šå¤„ç†ï¼Œå†è®¡ç®—å¯¹åº”çš„u
	Î±_opt = 10.0^(c)
	u_guess = copy(u_opt_vec[findmin(abs.(Î±_vec .- Î±_opt))[2]])
	u_opt, = my_newton(u -> J(u, Î±_opt), u -> H(u, Î±_opt), u_guess)

	#å¤åŸè¿”å›è¦æ±‚çš„A
	A_opt = A_vec(u_opt)


	function _loss(Ï‡Â²_vec1::Vector{Float64},G::Vector{Float64})
		_, _, c1, _ = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec1), guess_fit, Newton())[1]
		Î±_opt1 = 10.0^(c1)
		J1(u::Vector{Float64}, Î±::Float64) = Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))
		u_opt1, = my_newton(u -> J1(u, Î±_opt1), u -> H(u, Î±_opt1), u_opt)
		A_opt1 = A_vec(u_opt1)
		idx = findall(x -> x > 1e-3, A_opt)
		return sum(exp.(A_opt1[idx] - A_opt[idx]))*d
	end

	#=
	function _A_opt(Ï‡Â²_vec1::Vector{Float64},G::Vector{Float64})
		_, _, c, _ = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec1), guess_fit, Newton())[1]
		Î±_opt = 10.0^(c)
		J1(u::Vector{Float64}, Î±::Float64) = Î± * u + 1 / (Ïƒ^2) * (-diagm(S) * U' * G + d * diagm(S)^2 * V' * A_vec(u))
		u_opt1, = my_newton(u -> J1(u, Î±_opt), u -> H(u, Î±_opt), u_opt)
		A_opt1 = A_vec(u_opt1)
		return A_opt1
	end
	dA_optdivdÏ‡Â²_vec, âˆ‚A_optdivâˆ‚G = Zygote.jacobian(_A_opt, Ï‡Â²_vec, G)
	dA_optdivdG = dA_optdivdÏ‡Â²_vec*âˆ‚Ï‡Â²OPTdivâˆ‚G + âˆ‚A_optdivâˆ‚G
	@show dA_optdivdG[3,:]


	Î· = 1e-5
	Ï‡Â²_vec1 = Ï‡Â²_vec + Î· * dÎ±_optdivdÏ‡Â²_vec
	param1 = my_curve_fit(log10.(Î±_vec), log10.(Ï‡Â²_vec1), guess_fit, Newton())[1]
	c1 = param1[3]
	@show c1-c, Î·*sum(abs2.(dcdivdÏ‡Â²_vec))
	=#

	dlossdivdÏ‡Â² , âˆ‚lossdivâˆ‚G = Zygote.gradient(_loss, Ï‡Â²_vec, G)
	res = (âˆ‚Ï‡Â²OPTdivâˆ‚G)' * dlossdivdÏ‡Â² + âˆ‚lossdivâˆ‚G
	return res[1:N] + im * res[N+1:2*N], reach_tol
end
=#
